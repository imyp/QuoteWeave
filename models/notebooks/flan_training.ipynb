{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/jstet/quotes-500k/quotes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>attributed-no-source, best, life, love, mistak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You've gotta dance like there's nobody watchin...</td>\n",
       "      <td>William W. Purkey</td>\n",
       "      <td>dance, heaven, hurt, inspirational, life, love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You know you're in love when you can't fall as...</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>attributed-no-source, dreams, love, reality, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A friend is someone who knows all about you an...</td>\n",
       "      <td>Elbert Hubbard</td>\n",
       "      <td>friend, friendship, knowledge, love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Darkness cannot drive out darkness: only light...</td>\n",
       "      <td>Martin Luther King Jr., A Testament of Hope: T...</td>\n",
       "      <td>darkness, drive-out, hate, inspirational, ligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499704</th>\n",
       "      <td>I do believe the most important thing I can do...</td>\n",
       "      <td>John C. Stennis</td>\n",
       "      <td>Past, Believe, Help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499705</th>\n",
       "      <td>I'd say I'm a bit antimadridista although I do...</td>\n",
       "      <td>Isco</td>\n",
       "      <td>Team, Humility, Know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499706</th>\n",
       "      <td>The future is now.</td>\n",
       "      <td>Nam June Paik</td>\n",
       "      <td>Now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499707</th>\n",
       "      <td>In all my life and in the future, I will alway...</td>\n",
       "      <td>Norodom Sihamoni</td>\n",
       "      <td>Life, My Life, Servant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499708</th>\n",
       "      <td>The future is as bright as the promises of God.</td>\n",
       "      <td>William Carey</td>\n",
       "      <td>God, Promises, Bright</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499709 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    quote  \\\n",
       "0       I'm selfish, impatient and a little insecure. ...   \n",
       "1       You've gotta dance like there's nobody watchin...   \n",
       "2       You know you're in love when you can't fall as...   \n",
       "3       A friend is someone who knows all about you an...   \n",
       "4       Darkness cannot drive out darkness: only light...   \n",
       "...                                                   ...   \n",
       "499704  I do believe the most important thing I can do...   \n",
       "499705  I'd say I'm a bit antimadridista although I do...   \n",
       "499706                                 The future is now.   \n",
       "499707  In all my life and in the future, I will alway...   \n",
       "499708    The future is as bright as the promises of God.   \n",
       "\n",
       "                                                   author  \\\n",
       "0                                          Marilyn Monroe   \n",
       "1                                       William W. Purkey   \n",
       "2                                               Dr. Seuss   \n",
       "3                                          Elbert Hubbard   \n",
       "4       Martin Luther King Jr., A Testament of Hope: T...   \n",
       "...                                                   ...   \n",
       "499704                                    John C. Stennis   \n",
       "499705                                               Isco   \n",
       "499706                                      Nam June Paik   \n",
       "499707                                   Norodom Sihamoni   \n",
       "499708                                      William Carey   \n",
       "\n",
       "                                                 category  \n",
       "0       attributed-no-source, best, life, love, mistak...  \n",
       "1       dance, heaven, hurt, inspirational, life, love...  \n",
       "2       attributed-no-source, dreams, love, reality, s...  \n",
       "3                     friend, friendship, knowledge, love  \n",
       "4       darkness, drive-out, hate, inspirational, ligh...  \n",
       "...                                                   ...  \n",
       "499704                               Past, Believe, Help   \n",
       "499705                              Team, Humility, Know   \n",
       "499706                                               Now   \n",
       "499707                            Life, My Life, Servant   \n",
       "499708                             God, Promises, Bright   \n",
       "\n",
       "[499709 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bd4d6be82c45109b9b0e3e6e4a6c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/499709 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34f7599fcaa41f3bafb03d758e988ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/499709 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec72a9ebaa443849a031ad586540dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/499709 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import swifter\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "# Author should be truncated after first comma using apply\n",
    "data[\"author\"] = data[\"author\"].swifter.apply(\n",
    "    lambda x: x.split(\",\")[0] if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Rename category to categories\n",
    "data = data.rename(columns={\"category\": \"categories\"})\n",
    "\n",
    "data[\"categories\"] = data[\"categories\"].swifter.apply(\n",
    "    lambda x: \", \".join([tag.strip() for tag in str(x).split(\",\")])\n",
    ")\n",
    "\n",
    "# Remove the \"attributed-no-source\" category\n",
    "data[\"categories\"] = data[\"categories\"].swifter.apply(\n",
    "    lambda x: \", \".join(\n",
    "        [tag for tag in str(x).split(\",\") if tag != \"attributed-no-source\"]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data.sample(frac=0.2, random_state=42)\n",
    "data = data.drop(data_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>author</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>best,  life,  love,  mistakes,  out-of-contro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You've gotta dance like there's nobody watchin...</td>\n",
       "      <td>William W. Purkey</td>\n",
       "      <td>dance,  heaven,  hurt,  inspirational,  life, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A friend is someone who knows all about you an...</td>\n",
       "      <td>Elbert Hubbard</td>\n",
       "      <td>friend,  friendship,  knowledge,  love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Darkness cannot drive out darkness: only light...</td>\n",
       "      <td>Martin Luther King Jr.</td>\n",
       "      <td>darkness,  drive-out,  hate,  inspirational,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We accept the love we think we deserve.</td>\n",
       "      <td>Stephen Chbosky</td>\n",
       "      <td>inspirational,  love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499702</th>\n",
       "      <td>The future isn't just a place you'll go. It's ...</td>\n",
       "      <td>Nancy Duarte</td>\n",
       "      <td>You,  Place,  Will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499703</th>\n",
       "      <td>The Christian of the future will be a mystic o...</td>\n",
       "      <td>Karl Rahner</td>\n",
       "      <td>Christian,  Will,  Exist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499704</th>\n",
       "      <td>I do believe the most important thing I can do...</td>\n",
       "      <td>John C. Stennis</td>\n",
       "      <td>Past,  Believe,  Help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499706</th>\n",
       "      <td>The future is now.</td>\n",
       "      <td>Nam June Paik</td>\n",
       "      <td>Now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499707</th>\n",
       "      <td>In all my life and in the future, I will alway...</td>\n",
       "      <td>Norodom Sihamoni</td>\n",
       "      <td>Life,  My Life,  Servant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399767 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    quote  \\\n",
       "0       I'm selfish, impatient and a little insecure. ...   \n",
       "1       You've gotta dance like there's nobody watchin...   \n",
       "3       A friend is someone who knows all about you an...   \n",
       "4       Darkness cannot drive out darkness: only light...   \n",
       "5                 We accept the love we think we deserve.   \n",
       "...                                                   ...   \n",
       "499702  The future isn't just a place you'll go. It's ...   \n",
       "499703  The Christian of the future will be a mystic o...   \n",
       "499704  I do believe the most important thing I can do...   \n",
       "499706                                 The future is now.   \n",
       "499707  In all my life and in the future, I will alway...   \n",
       "\n",
       "                        author  \\\n",
       "0               Marilyn Monroe   \n",
       "1            William W. Purkey   \n",
       "3               Elbert Hubbard   \n",
       "4       Martin Luther King Jr.   \n",
       "5              Stephen Chbosky   \n",
       "...                        ...   \n",
       "499702            Nancy Duarte   \n",
       "499703             Karl Rahner   \n",
       "499704         John C. Stennis   \n",
       "499706           Nam June Paik   \n",
       "499707        Norodom Sihamoni   \n",
       "\n",
       "                                               categories  \n",
       "0        best,  life,  love,  mistakes,  out-of-contro...  \n",
       "1       dance,  heaven,  hurt,  inspirational,  life, ...  \n",
       "3                  friend,  friendship,  knowledge,  love  \n",
       "4       darkness,  drive-out,  hate,  inspirational,  ...  \n",
       "5                                    inspirational,  love  \n",
       "...                                                   ...  \n",
       "499702                                 You,  Place,  Will  \n",
       "499703                           Christian,  Will,  Exist  \n",
       "499704                              Past,  Believe,  Help  \n",
       "499706                                                Now  \n",
       "499707                           Life,  My Life,  Servant  \n",
       "\n",
       "[399767 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>author</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A black telephonereceiver was stuffed in the s...</td>\n",
       "      <td>M.L. Terese</td>\n",
       "      <td>detective,  mystery,  p-hone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bailey took an exasperated breath and sat up i...</td>\n",
       "      <td>Heather McVea</td>\n",
       "      <td>adolescence,  reason,  teenager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm getting a daily email from Microsoft which...</td>\n",
       "      <td>Steven Magee</td>\n",
       "      <td>10,  access,  account,  all,  along,  daily,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When you follow your heart you allow miraculou...</td>\n",
       "      <td>Menna van Praag</td>\n",
       "      <td>destiny,  dreams,  goals,  heart,  miracles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have been complaining so long about your l...</td>\n",
       "      <td>Israelmore Ayivor</td>\n",
       "      <td>accomplish,  accomplishment,  achievement,  ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               quote             author  \\\n",
       "0  A black telephonereceiver was stuffed in the s...        M.L. Terese   \n",
       "1  Bailey took an exasperated breath and sat up i...      Heather McVea   \n",
       "2  I'm getting a daily email from Microsoft which...       Steven Magee   \n",
       "3  When you follow your heart you allow miraculou...    Menna van Praag   \n",
       "4  You have been complaining so long about your l...  Israelmore Ayivor   \n",
       "\n",
       "                                          categories  \n",
       "0                       detective,  mystery,  p-hone  \n",
       "1                    adolescence,  reason,  teenager  \n",
       "2  10,  access,  account,  all,  along,  daily,  ...  \n",
       "3        destiny,  dreams,  goals,  heart,  miracles  \n",
       "4  accomplish,  accomplishment,  achievement,  ac...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data.sample(frac=0.99, random_state=42)\n",
    "data_val = data.drop(data_train.index)\n",
    "data_train = data_train.reset_index(drop=True)\n",
    "data_val = data_val.reset_index(drop=True)\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_text(quote, author):\n",
    "    \"\"\"Create the input text with descriptive prompt\"\"\"\n",
    "    return f'What tags or categories would best describe this quote: \"{quote}\" by {author}? Provide comma-separated tags.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_in_chunks(df, chunk_size=50000):\n",
    "    \"\"\"Process dataframe in chunks, returning a dataset\"\"\"\n",
    "\n",
    "    all_formatted_data = []\n",
    "\n",
    "    # Get total number of chunks for progress tracking\n",
    "    num_chunks = (len(df) + chunk_size - 1) // chunk_size\n",
    "\n",
    "    for i in tqdm(\n",
    "        range(0, len(df), chunk_size), total=num_chunks, desc=\"Processing chunks\"\n",
    "    ):\n",
    "        # Extract chunk\n",
    "        chunk = df.iloc[i : i + chunk_size].copy()\n",
    "\n",
    "        # Directly create input_text column (more efficient than apply)\n",
    "        chunk[\"input_text\"] = [\n",
    "            create_input_text(quote, author)\n",
    "            for quote, author in zip(chunk[\"quote\"], chunk[\"author\"])\n",
    "        ]\n",
    "\n",
    "        # Use existing categories column\n",
    "        chunk[\"target_text\"] = chunk[\"categories\"]\n",
    "\n",
    "        # Select only the columns we need\n",
    "        formatted_chunk = chunk[[\"input_text\", \"target_text\"]]\n",
    "\n",
    "        # Convert to records and add to result\n",
    "        all_formatted_data.extend(formatted_chunk.to_dict(\"records\"))\n",
    "\n",
    "    # Create dataset from all processed data\n",
    "    return Dataset.from_list(all_formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28fad7c96cf4f5590248aabe471035f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chunks:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a815d6eab7e49289b7b70bc75646397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0d72a509ab4828b3a773416f882e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/395769 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaebcf8463e406cab24efddf31bebc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process data in chunks\n",
    "train_dataset = process_data_in_chunks(data_train)\n",
    "val_dataset = process_data_in_chunks(data_val)\n",
    "\n",
    "# Save datasets to disk\n",
    "train_dataset.save_to_disk(\"train_dataset\")\n",
    "val_dataset.save_to_disk(\"val_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples[\"input_text\"], padding=\"max_length\", truncation=True, max_length=256\n",
    "    )\n",
    "    outputs = tokenizer(\n",
    "        examples[\"target_text\"], padding=\"max_length\", truncation=True, max_length=64\n",
    "    )\n",
    "\n",
    "    batch = {\n",
    "        \"input_ids\": inputs.input_ids,\n",
    "        \"attention_mask\": inputs.attention_mask,\n",
    "        \"labels\": outputs.input_ids.copy(),\n",
    "    }\n",
    "\n",
    "    # Replace pad token id with -100 so it's ignored in loss calculation\n",
    "    batch[\"labels\"] = [\n",
    "        [(label if label != tokenizer.pad_token_id else -100) for label in labels]\n",
    "        for labels in batch[\"labels\"]\n",
    "    ]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d0d2b63c974ad88c2b00f5d8b1c948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/395769 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True, num_proc=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08e2e5a48fe4bf8ba18edb37049a95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_val_dataset = val_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score, jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds, tokenizer):\n",
    "    \"\"\"\n",
    "    Compute metrics using semantic similarity and Jaccard similarity\n",
    "\n",
    "    Args:\n",
    "        eval_preds: Tuple containing (predictions, labels)\n",
    "        tokenizer: The tokenizer to decode predictions and labels\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with key metrics\n",
    "    \"\"\"\n",
    "    # Load sentence transformer model (only once)\n",
    "    global sentence_model\n",
    "    if \"sentence_model\" not in globals():\n",
    "        model_name = \"all-MiniLM-L6-v2\"\n",
    "        print(f\"Loading sentence transformer model: {model_name}\")\n",
    "        sentence_model = SentenceTransformer(model_name)\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        sentence_model.to(device)\n",
    "\n",
    "    # Decode predictions and labels\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # Clip predictions to vocab size and decode\n",
    "    preds = np.clip(preds, 0, tokenizer.vocab_size - 1)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 with pad token id in labels and decode\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Clean and process predictions and labels\n",
    "    processed_preds = []\n",
    "    processed_labels = []\n",
    "\n",
    "    for pred, label in zip(decoded_preds, decoded_labels):\n",
    "        # Simple processing - split by comma and clean\n",
    "        pred_tags = [tag.strip() for tag in pred.split(\",\") if tag.strip()]\n",
    "        label_tags = [tag.strip() for tag in label.split(\",\") if tag.strip()]\n",
    "\n",
    "        # Remove duplicates\n",
    "        pred_tags = list(dict.fromkeys(pred_tags))\n",
    "\n",
    "        processed_preds.append(\", \".join(pred_tags))\n",
    "        processed_labels.append(\", \".join(label_tags))\n",
    "\n",
    "    # Sample a subset for faster evaluation\n",
    "    max_examples = min(50, len(processed_preds))\n",
    "    sample_indices = np.random.choice(len(processed_preds), max_examples, replace=False)\n",
    "\n",
    "    sample_preds = [processed_preds[i] for i in sample_indices]\n",
    "    sample_labels = [processed_labels[i] for i in sample_indices]\n",
    "\n",
    "    # Calculate semantic similarity\n",
    "    with torch.no_grad():\n",
    "        pred_embeddings = sentence_model.encode(sample_preds)\n",
    "        label_embeddings = sentence_model.encode(sample_labels)\n",
    "\n",
    "    # Calculate cosine similarity for each pair\n",
    "    similarities = []\n",
    "    for i in range(len(pred_embeddings)):\n",
    "        sim = cosine_similarity(\n",
    "            pred_embeddings[i].reshape(1, -1), label_embeddings[i].reshape(1, -1)\n",
    "        )[0][0]\n",
    "        similarities.append(float(sim))\n",
    "\n",
    "    semantic_similarity = sum(similarities) / len(similarities) if similarities else 0.0\n",
    "\n",
    "    # Calculate Jaccard similarity\n",
    "    # Create a set of all unique tags\n",
    "    all_tags = set()\n",
    "    for pred, label in zip(sample_preds, sample_labels):\n",
    "        pred_tags = set(t.strip() for t in pred.split(\",\") if t.strip())\n",
    "        label_tags = set(t.strip() for t in label.split(\",\") if t.strip())\n",
    "        all_tags.update(pred_tags)\n",
    "        all_tags.update(label_tags)\n",
    "\n",
    "    all_tags = list(all_tags)\n",
    "\n",
    "    # Create multi-hot vectors for F1 and Jaccard calculations\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    for pred, label in zip(sample_preds, sample_labels):\n",
    "        pred_tags = set(t.strip() for t in pred.split(\",\") if t.strip())\n",
    "        label_tags = set(t.strip() for t in label.split(\",\") if t.strip())\n",
    "\n",
    "        true_vec = [1 if tag in label_tags else 0 for tag in all_tags]\n",
    "        pred_vec = [1 if tag in pred_tags else 0 for tag in all_tags]\n",
    "\n",
    "        true_labels.append(true_vec)\n",
    "        pred_labels.append(pred_vec)\n",
    "\n",
    "    # Calculate Jaccard score\n",
    "    jaccard = 0.0\n",
    "    if all_tags and any(true_labels) and any(pred_labels):\n",
    "        jaccard = jaccard_score(\n",
    "            y_true=true_labels, y_pred=pred_labels, average=\"macro\", zero_division=0\n",
    "        )\n",
    "\n",
    "    # Calculate final score\n",
    "    score = semantic_similarity + 100.0 * jaccard\n",
    "\n",
    "    # Print example outputs\n",
    "    num_examples = min(3, len(sample_preds))\n",
    "    for i in range(num_examples):\n",
    "        print(f\"\\nExample {i}:\")\n",
    "        print(f\"Prediction: {sample_preds[i]}\")\n",
    "        print(f\"Reference: {sample_labels[i]}\")\n",
    "        print(f\"Semantic similarity: {similarities[i]:.4f}\")\n",
    "        # Calculate Jaccard for this specific example\n",
    "        pred_tags = set(t.strip() for t in sample_preds[i].split(\",\") if t.strip())\n",
    "        label_tags = set(t.strip() for t in sample_labels[i].split(\",\") if t.strip())\n",
    "        if pred_tags or label_tags:\n",
    "            example_jaccard = (\n",
    "                len(pred_tags.intersection(label_tags))\n",
    "                / len(pred_tags.union(label_tags))\n",
    "                if pred_tags.union(label_tags)\n",
    "                else 0\n",
    "            )\n",
    "            print(f\"Jaccard similarity: {example_jaccard:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"semantic_similarity\": semantic_similarity,\n",
    "        \"jaccard_score\": jaccard,\n",
    "        \"score\": score,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggingTrainer(Seq2SeqTrainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Enhanced loss function for tag prediction that includes:\n",
    "        - Basic repetition penalty\n",
    "        - Malformed tag penalty\n",
    "        - Jaccard similarity bonus\n",
    "        \"\"\"\n",
    "        # Get standard loss using parent implementation\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Only apply custom loss during training\n",
    "        if self.args.do_train:\n",
    "            # Get the generated logits and batch size\n",
    "            logits = outputs.logits\n",
    "            batch_size = logits.shape[0]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Get predictions\n",
    "                generated_ids = torch.argmax(logits, dim=-1)\n",
    "                generated_texts = self.tokenizer.batch_decode(\n",
    "                    generated_ids, skip_special_tokens=True\n",
    "                )\n",
    "\n",
    "                # Get reference texts if available\n",
    "                labels = inputs.get(\"labels\", None)\n",
    "                reference_texts = None\n",
    "                if labels is not None:\n",
    "                    # Mask out padding tokens\n",
    "                    labels_masked = labels.clone()\n",
    "                    labels_masked[labels_masked == -100] = self.tokenizer.pad_token_id\n",
    "                    reference_texts = self.tokenizer.batch_decode(\n",
    "                        labels_masked, skip_special_tokens=True\n",
    "                    )\n",
    "\n",
    "                # Initialize loss components\n",
    "                repetition_penalty = 0.0\n",
    "                malformed_penalty = 0.0\n",
    "                jaccard_bonus = 0.0\n",
    "\n",
    "                for idx, text in enumerate(generated_texts):\n",
    "                    # Split by comma to get individual tags\n",
    "                    tags = [tag.strip() for tag in text.split(\",\") if tag.strip()]\n",
    "\n",
    "                    if not tags:\n",
    "                        continue\n",
    "\n",
    "                    # Process reference tags if available\n",
    "                    ref_tags = []\n",
    "                    if reference_texts and idx < len(reference_texts):\n",
    "                        ref_tags = [\n",
    "                            tag.strip()\n",
    "                            for tag in reference_texts[idx].split(\",\")\n",
    "                            if tag.strip()\n",
    "                        ]\n",
    "\n",
    "                    # Calculate repetition penalty\n",
    "                    unique_tags = set(tags)\n",
    "                    if len(tags) > 0:\n",
    "                        repetition_penalty += 1.0 - (len(unique_tags) / len(tags))\n",
    "\n",
    "                    # Simple malformed tag detection\n",
    "                    malformed_count = sum(\n",
    "                        1\n",
    "                        for tag in tags\n",
    "                        if (\n",
    "                            tag.endswith(\"-quot\")\n",
    "                            or tag.endswith(\"-s\")\n",
    "                            or tag.endswith(\"-\")\n",
    "                            or \"-quotes-quotes\" in tag\n",
    "                        )\n",
    "                    )\n",
    "                    if len(tags) > 0:\n",
    "                        malformed_penalty += malformed_count / len(tags)\n",
    "\n",
    "                    # Jaccard similarity calculation when reference is available\n",
    "                    if ref_tags and tags:\n",
    "                        pred_set = set(tags)\n",
    "                        ref_set = set(ref_tags)\n",
    "\n",
    "                        # Calculate Jaccard similarity (intersection over union)\n",
    "                        intersection = len(pred_set.intersection(ref_set))\n",
    "                        union = len(pred_set.union(ref_set))\n",
    "\n",
    "                        if union > 0:\n",
    "                            jaccard_score = intersection / union\n",
    "                            jaccard_bonus += jaccard_score\n",
    "\n",
    "                # Average metrics across batch\n",
    "                avg_repetition_penalty = (\n",
    "                    repetition_penalty / batch_size if batch_size > 0 else 0\n",
    "                )\n",
    "                avg_malformed_penalty = (\n",
    "                    malformed_penalty / batch_size if batch_size > 0 else 0\n",
    "                )\n",
    "                avg_jaccard_bonus = jaccard_bonus / batch_size if batch_size > 0 else 0\n",
    "\n",
    "                # Apply penalties and bonuses to loss with simple weights\n",
    "                custom_factor = (\n",
    "                    1.0\n",
    "                    + 0.5 * avg_repetition_penalty  # Repetition penalty\n",
    "                    + 0.3 * avg_malformed_penalty  # Malformation penalty\n",
    "                    - 100\n",
    "                    * avg_jaccard_bonus  # Jaccard similarity bonus (higher is better)\n",
    "                )\n",
    "\n",
    "                # Clip to reasonable range\n",
    "                custom_factor = max(0.8, min(1.5, custom_factor))\n",
    "\n",
    "                # Apply factor to base loss\n",
    "                loss = loss * custom_factor\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_wrapper(eval_preds):\n",
    "    return compute_metrics(eval_preds, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./flan-t5-semantic-tagger\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"score\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "# Update the model's generation config directly\n",
    "model.config.no_repeat_ngram_size = 2  # Prevents repeating 2-grams\n",
    "model.config.repetition_penalty = 2.0  # Penalizes token repetition\n",
    "model.config.diversity_penalty = 0.0  # Diversity penalty is not used in order to trigger beam search\n",
    "model.config.num_beam_groups = 1  # Diverse beam groups\n",
    "model.config.num_beams = 5  # Beam search for better quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TaggingTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_wrapper,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2319' max='2319' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2319/2319 2:58:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Semantic Similarity</th>\n",
       "      <th>Jaccard Score</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.749800</td>\n",
       "      <td>2.528320</td>\n",
       "      <td>0.371057</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>5.132962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.682300</td>\n",
       "      <td>2.462891</td>\n",
       "      <td>0.447852</td>\n",
       "      <td>0.059561</td>\n",
       "      <td>6.403964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.653700</td>\n",
       "      <td>2.430664</td>\n",
       "      <td>0.426922</td>\n",
       "      <td>0.060658</td>\n",
       "      <td>6.492681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.627000</td>\n",
       "      <td>2.411621</td>\n",
       "      <td>0.423445</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>3.285899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.626400</td>\n",
       "      <td>2.402588</td>\n",
       "      <td>0.422339</td>\n",
       "      <td>0.056985</td>\n",
       "      <td>6.120869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.619500</td>\n",
       "      <td>2.396240</td>\n",
       "      <td>0.450072</td>\n",
       "      <td>0.049231</td>\n",
       "      <td>5.373173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.613900</td>\n",
       "      <td>2.392090</td>\n",
       "      <td>0.463997</td>\n",
       "      <td>0.063635</td>\n",
       "      <td>6.827469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.603500</td>\n",
       "      <td>2.391113</td>\n",
       "      <td>0.463316</td>\n",
       "      <td>0.063107</td>\n",
       "      <td>6.773996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.608600</td>\n",
       "      <td>2.390137</td>\n",
       "      <td>0.449764</td>\n",
       "      <td>0.064981</td>\n",
       "      <td>6.947891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.609700</td>\n",
       "      <td>2.390625</td>\n",
       "      <td>0.454804</td>\n",
       "      <td>0.073995</td>\n",
       "      <td>7.854331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.606400</td>\n",
       "      <td>2.389648</td>\n",
       "      <td>0.487722</td>\n",
       "      <td>0.085227</td>\n",
       "      <td>9.010449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/repos/github/QuoteWeave/models/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1667: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 0:\n",
      "Prediction: great-soul, soul-quotes\n",
      "Reference: amazing, confidence, excellent-life, inspirational, lailah-gifty-akita-affirmations, self-esteem, self-love, self-mootivation, shine-your-light, soul-great-soul, wonderful-people, your-life\n",
      "Semantic similarity: 0.3310\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 1:\n",
      "Prediction: money, money-quotes\n",
      "Reference: one, day\n",
      "Semantic similarity: 0.1701\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 2:\n",
      "Prediction: confidential-relationships, confidentiality, privacy-quotes\n",
      "Reference: confidence, relationships\n",
      "Semantic similarity: 0.4632\n",
      "Jaccard similarity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/repos/github/QuoteWeave/models/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'num_beams': 5, 'repetition_penalty': 2.0, 'no_repeat_ngram_size': 2}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 0:\n",
      "Prediction: success, success-quotes\n",
      "Reference: Make It Happen, You, Happen\n",
      "Semantic similarity: 0.2621\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 1:\n",
      "Prediction: menace, menace-quotes\n",
      "Reference: male, men, menace\n",
      "Semantic similarity: 0.6182\n",
      "Jaccard similarity: 0.2500\n",
      "\n",
      "Example 2:\n",
      "Prediction: actor, actors, simian-performance-coach, peter-elliott\n",
      "Reference: Time, Good, Performance\n",
      "Semantic similarity: 0.2064\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 0:\n",
      "Prediction: poetry, poetry-quotes, kate-tei-yamashita\n",
      "Reference: characters, identity, karen-tei-yamashita, poems, poet, poetry, poets, self, stories, tropic-of-orange\n",
      "Semantic similarity: 0.6919\n",
      "Jaccard similarity: 0.0833\n",
      "\n",
      "Example 1:\n",
      "Prediction: love-quotes, christianity\n",
      "Reference: coming-of-age, edgy-teen-fiction, inspirational-love, new-adult-contemporary-romance, teen-romance, young-adult-romance\n",
      "Semantic similarity: 0.2267\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 2:\n",
      "Prediction: love-quotes, losing-yourself, forgetting-that-you-are-special\n",
      "Reference: love, pain, relationships, self\n",
      "Semantic similarity: 0.5592\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 0:\n",
      "Prediction: road, roads, plowing\n",
      "Reference: christmas, endurance, inspirational, labor, love, persistence, practice, resilience\n",
      "Semantic similarity: 0.2828\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 1:\n",
      "Prediction: faith, christianity\n",
      "Reference: Life, Test, Him\n",
      "Semantic similarity: 0.3249\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 2:\n",
      "Prediction: a-shot-at-love, love\n",
      "Reference: motherhood, sign-of-life, single-parenting\n",
      "Semantic similarity: 0.2525\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 0:\n",
      "Prediction: christian-quotes, religion, faith, spirituality, inspirational, quotes, quote-from-tronon-lee-stewart\n",
      "Reference: courage, guts\n",
      "Semantic similarity: 0.2511\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 1:\n",
      "Prediction: betray-me, kill-my-self, try-to-kill-yourself\n",
      "Reference: betrayal, kill, sith, star-wars\n",
      "Semantic similarity: 0.5155\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 2:\n",
      "Prediction: baptism, christianity, grace\n",
      "Reference: baptism, christian, inspiration, inspirational, jesus-christ, theology\n",
      "Semantic similarity: 0.7811\n",
      "Jaccard similarity: 0.1250\n",
      "\n",
      "Example 0:\n",
      "Prediction: adventure, love, mess\n",
      "Reference: Steve Maraboli\n",
      "Semantic similarity: 0.0837\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 1:\n",
      "Prediction: curiosity, women, snooping\n",
      "Reference: curiosity, insight, intuition, power, trivialization-of-women, wild-woman, women-who-run-with-wolves\n",
      "Semantic similarity: 0.5500\n",
      "Jaccard similarity: 0.1111\n",
      "\n",
      "Example 2:\n",
      "Prediction: a-successful-response\n",
      "Reference: inspirational, promises\n",
      "Semantic similarity: 0.3688\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 0:\n",
      "Prediction: adversity, self-help\n",
      "Reference: manhood, passivity, positive-thinking, positivity, self-control, self-help\n",
      "Semantic similarity: 0.4561\n",
      "Jaccard similarity: 0.1429\n",
      "\n",
      "Example 1:\n",
      "Prediction: human-wisdom, nhat-hanh\n",
      "Reference: Lost, Worry, Hearts\n",
      "Semantic similarity: 0.1516\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 2:\n",
      "Prediction: art, passion, value\n",
      "Reference: art, combine, create, happy, passion, process, purpose, skill, smart, strength, useful, value\n",
      "Semantic similarity: 0.6936\n",
      "Jaccard similarity: 0.2500\n",
      "\n",
      "Example 0:\n",
      "Prediction: parenting, parenting-quotes\n",
      "Reference: Good, Perspective, Parent\n",
      "Semantic similarity: 0.4911\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 1:\n",
      "Prediction: good-deeds, soul-garden\n",
      "Reference: deeds, good, humanity-advice, inspirational, positive-outlook, self-motivation, soul, spiritual, wisdom-of-lailah-gifty-akita, your-life\n",
      "Semantic similarity: 0.4774\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 2:\n",
      "Prediction: confidence, ezra-and-cortez\n",
      "Reference: bdsm, erotica\n",
      "Semantic similarity: 0.0371\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 0:\n",
      "Prediction: winter, moon, light\n",
      "Reference: snow, winter\n",
      "Semantic similarity: 0.6521\n",
      "Jaccard similarity: 0.2500\n",
      "\n",
      "Example 1:\n",
      "Prediction: battle, fight, victory\n",
      "Reference: freedom, war\n",
      "Semantic similarity: 0.5629\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 2:\n",
      "Prediction: christianity, god, prayer\n",
      "Reference: God, Win, Think\n",
      "Semantic similarity: 0.3970\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 0:\n",
      "Prediction: healing, healing-quotes, spiritual-restoration, phindiwe-nkosi\n",
      "Reference: book, conscience, conscious, consciousness, faith, healing, hope, lost, moon, new, pain, sun\n",
      "Semantic similarity: 0.5652\n",
      "Jaccard similarity: 0.0667\n",
      "\n",
      "Example 1:\n",
      "Prediction: buffalo, buffalo-man, neil-gaiman\n",
      "Reference: believe\n",
      "Semantic similarity: 0.0834\n",
      "Jaccard similarity: 0.0000\n",
      "\n",
      "Example 2:\n",
      "Prediction: winter, violinist, summer-light, h.s.-crow\n",
      "Reference: change, haiku, haiku-quotes, haikus, nature, preparation, seasons-of-life, summer, violinist, winter\n",
      "Semantic similarity: 0.5212\n",
      "Jaccard similarity: 0.1667\n",
      "\n",
      "Example 0:\n",
      "Prediction: adventure, reading\n",
      "Reference: habits, learning, life, life-and-living, positive-attitude, reading, self-confidence, self-education, self-motivation\n",
      "Semantic similarity: 0.2182\n",
      "Jaccard similarity: 0.1000\n",
      "\n",
      "Example 1:\n",
      "Prediction: forgiveness, forgiveness-quotes\n",
      "Reference: compassion, forgiveness, forgiveness-quotes, kindness, love, mercy, power, richelle, richelle-e-goodrich, richelle-goodrich\n",
      "Semantic similarity: 0.4998\n",
      "Jaccard similarity: 0.2000\n",
      "\n",
      "Example 2:\n",
      "Prediction: lady, gwenn-wright\n",
      "Reference: cheating, gothic, gwenn-wright, love, relationships, romance, von-strassenberg, ya, young-adult\n",
      "Semantic similarity: 0.4103\n",
      "Jaccard similarity: 0.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2319, training_loss=2.6462813982319964, metrics={'train_runtime': 10717.2795, 'train_samples_per_second': 110.784, 'train_steps_per_second': 0.216, 'total_flos': 4.065085989314888e+17, 'train_loss': 2.6462813982319964, 'epoch': 3.0})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"flan-t5-semantic-tagger-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('flan-t5-semantic-tagger-base/tokenizer_config.json',\n",
       " 'flan-t5-semantic-tagger-base/special_tokens_map.json',\n",
       " 'flan-t5-semantic-tagger-base/spiece.model',\n",
       " 'flan-t5-semantic-tagger-base/added_tokens.json')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.processing_class.save_pretrained(\"flan-t5-semantic-tagger-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>author</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179178</th>\n",
       "      <td>The sting of her abandonment had not lessened ...</td>\n",
       "      <td>T.J. Forrester</td>\n",
       "      <td>love,  relationship,  suffering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183253</th>\n",
       "      <td>Everything that falls upon the eye is an appar...</td>\n",
       "      <td>Marilynn Robinson in Housekeeping</td>\n",
       "      <td>grief,  loss,  memory,  remembering-the-good, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84139</th>\n",
       "      <td>I don't hate Republicans as individuals. But I...</td>\n",
       "      <td>Howard Dean</td>\n",
       "      <td>politics,  republicans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272877</th>\n",
       "      <td>Think More Not Less.</td>\n",
       "      <td>Jelani Payne</td>\n",
       "      <td>critical-thinking,  perspective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195518</th>\n",
       "      <td>Some individuals have the courage to make it, ...</td>\n",
       "      <td>Gino SegrÃ¨</td>\n",
       "      <td>comfortable,  dream,  inspirational,  journey,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116792</th>\n",
       "      <td>I've found time can heal most anything and you...</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>fifteen,  music,  taylor-swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256026</th>\n",
       "      <td>The whole universe is but a huge Symbol of god\".</td>\n",
       "      <td>Thomas Carlyle</td>\n",
       "      <td>god,  sprituality,  universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390073</th>\n",
       "      <td>I am so over you, Rejection. You can't get to ...</td>\n",
       "      <td>Buffy Andrews</td>\n",
       "      <td>quotes,  writers-life,  writers-quotes,  write...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366700</th>\n",
       "      <td>I try to live my life every day in the present...</td>\n",
       "      <td>Susan Sarandon</td>\n",
       "      <td>activism,  injustice,  life,  need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169145</th>\n",
       "      <td>I stuff my mouth with old fabric and scream un...</td>\n",
       "      <td>Laurie Halse Anderson</td>\n",
       "      <td>depression,  school</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99942 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    quote  \\\n",
       "179178  The sting of her abandonment had not lessened ...   \n",
       "183253  Everything that falls upon the eye is an appar...   \n",
       "84139   I don't hate Republicans as individuals. But I...   \n",
       "272877                               Think More Not Less.   \n",
       "195518  Some individuals have the courage to make it, ...   \n",
       "...                                                   ...   \n",
       "116792  I've found time can heal most anything and you...   \n",
       "256026   The whole universe is but a huge Symbol of god\".   \n",
       "390073  I am so over you, Rejection. You can't get to ...   \n",
       "366700  I try to live my life every day in the present...   \n",
       "169145  I stuff my mouth with old fabric and scream un...   \n",
       "\n",
       "                                   author  \\\n",
       "179178                     T.J. Forrester   \n",
       "183253  Marilynn Robinson in Housekeeping   \n",
       "84139                         Howard Dean   \n",
       "272877                       Jelani Payne   \n",
       "195518                         Gino SegrÃ¨   \n",
       "...                                   ...   \n",
       "116792                       Taylor Swift   \n",
       "256026                     Thomas Carlyle   \n",
       "390073                      Buffy Andrews   \n",
       "366700                     Susan Sarandon   \n",
       "169145              Laurie Halse Anderson   \n",
       "\n",
       "                                               categories  \n",
       "179178                    love,  relationship,  suffering  \n",
       "183253  grief,  loss,  memory,  remembering-the-good, ...  \n",
       "84139                              politics,  republicans  \n",
       "272877                    critical-thinking,  perspective  \n",
       "195518  comfortable,  dream,  inspirational,  journey,...  \n",
       "...                                                   ...  \n",
       "116792                     fifteen,  music,  taylor-swift  \n",
       "256026                       god,  sprituality,  universe  \n",
       "390073  quotes,  writers-life,  writers-quotes,  write...  \n",
       "366700                 activism,  injustice,  life,  need  \n",
       "169145                                depression,  school  \n",
       "\n",
       "[99942 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e66dd5bb914bc9a3f6cdde50b1b1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chunks:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = process_data_in_chunks(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba57cc87946e42bb88684b6a041a38ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/99942 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset.save_to_disk(\"test_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path):\n",
    "    \"\"\"\n",
    "    Load the trained model and tokenizer from the specified path\n",
    "    \"\"\"\n",
    "    print(f\"Loading model and tokenizer from {model_path}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path, torch_dtype=torch.bfloat16)\n",
    "    \n",
    "    # Update the model's generation config for better tag generation\n",
    "    model.config.no_repeat_ngram_size = 2    # Prevents repeating 2-grams\n",
    "    model.config.repetition_penalty = 2.0    # Penalizes token repetition\n",
    "    model.config.diversity_penalty = 0.0     # No diversity penalty to trigger beam search\n",
    "    model.config.num_beam_groups = 1         # Diverse beam groups\n",
    "    model.config.num_beams = 5               # Beam search for better quality\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tags(model, tokenizer, text, max_length=128):\n",
    "    \"\"\"\n",
    "    Generate tags for a given text using the trained model\n",
    "    \"\"\"\n",
    "    # Prepare the input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    input_ids = inputs.input_ids\n",
    "    \n",
    "    # Move to the same device as model\n",
    "    device = model.device\n",
    "    input_ids = input_ids.to(device)\n",
    "    \n",
    "    # Generate tags\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=max_length,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "    \n",
    "    # Decode the generated tokens\n",
    "    predicted_tags = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Clean up tags - split by comma and strip whitespace\n",
    "    tags = [tag.strip() for tag in predicted_tags.split(\",\") if tag.strip()]\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_tags = []\n",
    "    for tag in tags:\n",
    "        if tag not in unique_tags:\n",
    "            unique_tags.append(tag)\n",
    "    \n",
    "    return unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_deduplicate_tags(tags):\n",
    "    \"\"\"\n",
    "    Clean and deduplicate a list of tags\n",
    "    \"\"\"\n",
    "    # Simple clean up - strip whitespace\n",
    "    cleaned_tags = [tag.strip() for tag in tags if tag.strip()]\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_tags = []\n",
    "    for tag in cleaned_tags:\n",
    "        if tag not in unique_tags and not any(\n",
    "            tag.endswith(suffix) for suffix in [\"-quot\", \"-s\", \"-\"]\n",
    "        ):\n",
    "            unique_tags.append(tag)\n",
    "    \n",
    "    return unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(model, tokenizer, test_dataset, num_examples=None):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a test dataset\n",
    "    \"\"\"\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "\n",
    "    results = []\n",
    "    similarities = []\n",
    "    jaccard_scores = []\n",
    "\n",
    "    # Initialize the sentence transformer for semantic similarity\n",
    "    global sentence_model\n",
    "    if \"sentence_model\" not in globals():\n",
    "        print(\"Loading sentence transformer model\")\n",
    "        model_name = \"all-MiniLM-L6-v2\"\n",
    "        sentence_model = SentenceTransformer(model_name)\n",
    "        sentence_model.to(device)\n",
    "\n",
    "    # Limit examples if specified\n",
    "    if num_examples is not None and num_examples < len(test_dataset):\n",
    "        test_dataset = test_dataset.select(range(num_examples))\n",
    "\n",
    "    print(f\"Evaluating on {len(test_dataset)} examples...\")\n",
    "\n",
    "    for idx, example in enumerate(tqdm(test_dataset)):\n",
    "        text = example[\"input_text\"]\n",
    "        reference_tags = (\n",
    "            example[\"target_text\"].split(\", \")\n",
    "            if isinstance(example[\"target_text\"], str)\n",
    "            else example[\"target_text\"]\n",
    "        )\n",
    "        reference_tags = clean_and_deduplicate_tags(reference_tags)\n",
    "\n",
    "        # Generate predictions\n",
    "        predicted_tags = predict_tags(model, tokenizer, text)\n",
    "\n",
    "        # Calculate metrics\n",
    "        # 1. Jaccard similarity\n",
    "        pred_set = set(predicted_tags)\n",
    "        ref_set = set(reference_tags)\n",
    "\n",
    "        jaccard = 0.0\n",
    "        if pred_set or ref_set:  # Avoid division by zero\n",
    "            intersection = len(pred_set.intersection(ref_set))\n",
    "            union = len(pred_set.union(ref_set))\n",
    "            jaccard = intersection / union if union > 0 else 0.0\n",
    "\n",
    "        # 2. Semantic similarity using sentence transformer\n",
    "        pred_text = \", \".join(predicted_tags)\n",
    "        ref_text = \", \".join(reference_tags)\n",
    "\n",
    "        # Encode texts\n",
    "        with torch.no_grad():\n",
    "            pred_embedding = sentence_model.encode(pred_text, convert_to_tensor=True)\n",
    "            ref_embedding = sentence_model.encode(ref_text, convert_to_tensor=True)\n",
    "\n",
    "            # Calculate cosine similarity\n",
    "            similarity = cosine_similarity(\n",
    "                pred_embedding.cpu().numpy().reshape(1, -1),\n",
    "                ref_embedding.cpu().numpy().reshape(1, -1),\n",
    "            )[0][0]\n",
    "\n",
    "        # Store results\n",
    "        result = {\n",
    "            \"text\": text[:200] + \"...\",  # Truncate for display\n",
    "            \"reference_tags\": reference_tags,\n",
    "            \"predicted_tags\": predicted_tags,\n",
    "            \"jaccard_score\": jaccard,\n",
    "            \"semantic_similarity\": similarity,\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "        jaccard_scores.append(jaccard)\n",
    "        similarities.append(similarity)\n",
    "\n",
    "        # Print examples (first 3)\n",
    "        if idx < 3:\n",
    "            print(f\"\\nExample {idx}:\")\n",
    "            print(f\"Text: {text[:100]}...\")\n",
    "            print(f\"Reference tags: {', '.join(reference_tags)}\")\n",
    "            print(f\"Predicted tags: {', '.join(predicted_tags)}\")\n",
    "            print(f\"Jaccard score: {jaccard:.4f}\")\n",
    "            print(f\"Semantic similarity: {similarity:.4f}\")\n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_jaccard = sum(jaccard_scores) / len(jaccard_scores) if jaccard_scores else 0\n",
    "    avg_similarity = sum(similarities) / len(similarities) if similarities else 0\n",
    "\n",
    "    # Calculate combined score (same as in compute_metrics)\n",
    "    combined_score = avg_similarity + 2.0 * avg_jaccard\n",
    "\n",
    "    # Print overall results\n",
    "    print(\"\\nOverall Results:\")\n",
    "    print(f\"Average Jaccard Score: {avg_jaccard:.4f}\")\n",
    "    print(f\"Average Semantic Similarity: {avg_similarity:.4f}\")\n",
    "    print(f\"Combined Score: {combined_score:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"metrics\": {\n",
    "            \"jaccard_score\": avg_jaccard,\n",
    "            \"semantic_similarity\": avg_similarity,\n",
    "            \"combined_score\": combined_score,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer from flan-t5-semantic-tagger-base\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"flan-t5-semantic-tagger-base\"\n",
    "model, tokenizer = load_model_and_tokenizer(model_path)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_from_disk(\"test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 100 examples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8042105ee19445091a07c00f98cdfd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 0:\n",
      "Text: What tags or categories would best describe this quote: \"The sting of her abandonment had not lessen...\n",
      "Reference tags: love, relationship, suffering\n",
      "Predicted tags: abandonment, t.j.-forrester\n",
      "Jaccard score: 0.0000\n",
      "Semantic similarity: 0.2328\n",
      "\n",
      "Example 1:\n",
      "Text: What tags or categories would best describe this quote: \"Everything that falls upon the eye is an ap...\n",
      "Reference tags: grief, loss, memory, remembering-the-good, time\n",
      "Predicted tags: apparition, perishable\n",
      "Jaccard score: 0.0000\n",
      "Semantic similarity: 0.2068\n",
      "\n",
      "Example 2:\n",
      "Text: What tags or categories would best describe this quote: \"I don't hate Republicans as individuals. Bu...\n",
      "Reference tags: politics, republicans\n",
      "Predicted tags: America, Hate, Individuals\n",
      "Jaccard score: 0.0000\n",
      "Semantic similarity: 0.5124\n",
      "\n",
      "Overall Results:\n",
      "Average Jaccard Score: 0.1145\n",
      "Average Semantic Similarity: 0.4382\n",
      "Combined Score: 0.6672\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_results = evaluate_on_test_set(model, tokenizer, test_dataset, num_examples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed and results saved to evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "with open(\"evaluation_results_base.json\", \"w\") as f:\n",
    "    # Convert results to serializable format\n",
    "    serializable_results = {\n",
    "        \"metrics\": test_results[\"metrics\"],\n",
    "        \"examples\": [\n",
    "            {\n",
    "                \"text\": r[\"text\"],\n",
    "                \"reference_tags\": r[\"reference_tags\"],\n",
    "                \"predicted_tags\": r[\"predicted_tags\"],\n",
    "                \"jaccard_score\": r[\"jaccard_score\"],\n",
    "                \"semantic_similarity\": r[\"semantic_similarity\"],\n",
    "            }\n",
    "            for r in test_results[\"results\"][:10]  # Save first 10 examples\n",
    "        ],\n",
    "    }\n",
    "    json.dump(serializable_results, f, indent=2, cls=NumpyEncoder)\n",
    "\n",
    "print(\"Evaluation completed and results saved to evaluation_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained small model and tokenizer\n",
    "model_path = \"flan-t5-semantic-tagger-small\"\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_path, torch_dtype=torch.bfloat16)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "T5ForConditionalGeneration.__init__() got an unexpected keyword argument 'to_pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_pt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m tokenizer = AutoTokenizer.from_pretrained(\n\u001b[32m      5\u001b[39m     model_path, use_fast=\u001b[38;5;28;01mTrue\u001b[39;00m, local_files_only=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/repos/github/QuoteWeave/models/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/repos/github/QuoteWeave/models/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:279\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    281\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/repos/github/QuoteWeave/models/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:4342\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4336\u001b[39m     config = \u001b[38;5;28mcls\u001b[39m._autoset_attn_implementation(\n\u001b[32m   4337\u001b[39m         config, use_flash_attention_2=use_flash_attention_2, torch_dtype=torch_dtype, device_map=device_map\n\u001b[32m   4338\u001b[39m     )\n\u001b[32m   4340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(model_init_context):\n\u001b[32m   4341\u001b[39m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4342\u001b[39m     model = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4344\u001b[39m \u001b[38;5;66;03m# Make sure to tie the weights correctly\u001b[39;00m\n\u001b[32m   4345\u001b[39m model.tie_weights()\n",
      "\u001b[31mTypeError\u001b[39m: T5ForConditionalGeneration.__init__() got an unexpected keyword argument 'to_pt'"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_path, torch_dtype=torch.float32, local_files_only=True, to_pt=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path, use_fast=True, local_files_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e463fc679e94802b299cf878c1a2a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f71b8826850>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/repos/github/QuoteWeave/models/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m.push_to_hub(\u001b[33m\"\u001b[39m\u001b[33mfristrup/flan-t5-semantic-tagger-small\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m tokenizer.push_to_hub(\u001b[33m\"\u001b[39m\u001b[33mfristrup/flan-t5-semantic-tagger-small\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.push_to_hub(\"fristrup/flan-t5-semantic-tagger-small\")\n",
    "tokenizer.push_to_hub(\"fristrup/flan-t5-semantic-tagger-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "inference_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"fristrup/flan-t5-semantic-tagger-small\", torch_dtype=torch.float32, local_files_only=True\n",
    ")\n",
    "inference_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"fristrup/flan-t5-semantic-tagger-small\", use_fast=True, local_files_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hf://datasets/jstet/quotes-500k/quotes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer from fristrup/flan-t5-semantic-tagger-small\n"
     ]
    }
   ],
   "source": [
    "inference_model, inference_tokenizer = load_model_and_tokenizer(\"fristrup/flan-t5-semantic-tagger-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selfish', 'impatient', 'insecure']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_tags(inference_model, inference_tokenizer, create_input_text(df[\"quote\"].iloc[0], df[\"author\"].iloc[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
